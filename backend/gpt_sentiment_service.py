"""
Service d'analyse de sentiment intelligent avec GPT-4.1-mini
Remplace l'analyse locale par une analyse contextuelle et pr√©cise
Optimis√© pour le contexte fran√ßais et guadeloup√©en
"""
import logging
import os
from typing import Dict, List, Any, Optional
from datetime import datetime
import json
from openai import OpenAI

# Configuration logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class GptSentimentAnalyzer:
    def __init__(self):
        """Initialiser l'analyseur de sentiment GPT"""
        
        # Configuration OpenAI
        self.openai_api_key = os.environ.get('OPENAI_API_KEY')
        if not self.openai_api_key:
            logger.error("‚ùå OPENAI_API_KEY non configur√©e")
            self.client = None
        else:
            try:
                self.client = OpenAI(api_key=self.openai_api_key)
                logger.info("‚úÖ Client OpenAI initialis√© pour analyse de sentiment")
            except Exception as e:
                logger.error(f"‚ùå Erreur initialisation OpenAI: {e}")
                self.client = None
        
        # Template de prompt pour l'analyse de sentiment
        self.sentiment_prompt_template = """Analysez le sentiment de ce texte en fran√ßais dans le contexte de la Guadeloupe et des Antilles.

TEXTE √Ä ANALYSER:
"{text}"

INSTRUCTIONS:
1. Analysez le sentiment global (positif, n√©gatif, neutre)
2. Donnez un score pr√©cis de -1.0 (tr√®s n√©gatif) √† +1.0 (tr√®s positif) 
3. √âvaluez l'intensit√© (faible, mod√©r√©e, forte)
4. Identifiez les √©motions principales
5. Expliquez les raisons du sentiment
6. D√©tectez les sujets/th√®mes abord√©s
7. Contextualisez pour la Guadeloupe si pertinent

R√âPONDEZ UNIQUEMENT EN JSON VALIDE:
{{
    "sentiment": "positif|n√©gatif|neutre",
    "score": 0.0,
    "intensite": "faible|mod√©r√©e|forte", 
    "emotions": ["joie", "espoir", "inqui√©tude", "col√®re", "surprise", "tristesse"],
    "raisons": "Explication du sentiment d√©tect√©e",
    "themes": ["politique", "√©conomie", "social", "culture", "environnement"],
    "contexte_guadeloupe": "Pertinence pour la Guadeloupe",
    "mots_cles": ["mot1", "mot2", "mot3"],
    "confiance": 0.0
}}"""

    def analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """Analyser le sentiment d'un texte avec GPT"""
        try:
            if not text or not text.strip():
                return self._default_sentiment()
            
            if not self.client:
                logger.warning("‚ö†Ô∏è Client OpenAI non disponible, utilisation du fallback")
                return self._fallback_sentiment_analysis(text)
            
            # Nettoyer et pr√©parer le texte
            clean_text = self._clean_text(text)
            if len(clean_text) > 3000:  # Limiter pour les co√ªts
                clean_text = clean_text[:3000] + "..."
            
            # Cr√©er le prompt
            prompt = self.sentiment_prompt_template.format(text=clean_text)
            
            # Appel √† GPT
            logger.info(f"ü§ñ Analyse GPT sentiment pour texte de {len(clean_text)} caract√®res")
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": "Tu es un expert en analyse de sentiment sp√©cialis√© dans le contexte fran√ßais et antillais. Tu r√©ponds toujours en JSON valide."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                max_tokens=500,
                temperature=0.1  # Peu de cr√©ativit√© pour la consistance
            )
            
            # Extraire et parser la r√©ponse
            gpt_response = response.choices[0].message.content.strip()
            
            try:
                # Parser le JSON
                sentiment_data = json.loads(gpt_response)
                
                # Normaliser et valider les donn√©es
                analyzed_sentiment = self._normalize_gpt_response(sentiment_data, text)
                
                logger.info(f"‚úÖ Analyse GPT termin√©e: {analyzed_sentiment['polarity']} (score: {analyzed_sentiment['score']})")
                return analyzed_sentiment
                
            except json.JSONDecodeError as e:
                logger.warning(f"‚ö†Ô∏è Erreur parsing JSON GPT: {e}")
                logger.warning(f"R√©ponse GPT: {gpt_response}")
                return self._fallback_sentiment_analysis(clean_text)
                
        except Exception as e:
            logger.error(f"‚ùå Erreur analyse GPT sentiment: {e}")
            return self._fallback_sentiment_analysis(text)

    def _clean_text(self, text: str) -> str:
        """Nettoyer le texte pour l'analyse"""
        if not text:
            return ""
        
        # Supprimer les caract√®res de contr√¥le
        import re
        clean_text = re.sub(r'[\x00-\x1f\x7f-\x9f]', ' ', text)
        
        # Remplacer les espaces multiples
        clean_text = re.sub(r'\s+', ' ', clean_text)
        
        return clean_text.strip()

    def _normalize_gpt_response(self, gpt_data: Dict, original_text: str) -> Dict[str, Any]:
        """Normaliser la r√©ponse GPT au format attendu"""
        
        # Mapping des sentiments
        sentiment_mapping = {
            'positif': 'positive',
            'n√©gatif': 'negative', 
            'negatif': 'negative',
            'neutre': 'neutral'
        }
        
        # Mapping des intensit√©s
        intensity_mapping = {
            'faible': 'weak',
            'mod√©r√©e': 'moderate',  
            'moderee': 'moderate',
            'mod√©r√©': 'moderate',
            'modere': 'moderate',
            'forte': 'strong'
        }
        
        # Extraire et normaliser les donn√©es
        sentiment = gpt_data.get('sentiment', 'neutre').lower()
        polarity = sentiment_mapping.get(sentiment, 'neutral')
        
        score = float(gpt_data.get('score', 0.0))
        score = max(-1.0, min(1.0, score))  # Clamp entre -1 et 1
        
        intensite = gpt_data.get('intensite', 'faible').lower()
        intensity = intensity_mapping.get(intensite, 'weak')
        
        emotions = gpt_data.get('emotions', [])
        if not isinstance(emotions, list):
            emotions = []
        
        themes = gpt_data.get('themes', [])
        if not isinstance(themes, list):
            themes = []
        
        mots_cles = gpt_data.get('mots_cles', [])
        if not isinstance(mots_cles, list):
            mots_cles = []
        
        confiance = float(gpt_data.get('confiance', 0.8))
        confiance = max(0.0, min(1.0, confiance))
        
        return {
            'polarity': polarity,
            'score': round(score, 3),
            'intensity': intensity,
            'positive_score': max(0, score) if score > 0 else 0.0,
            'negative_score': abs(min(0, score)) if score < 0 else 0.0,
            'word_count': len(original_text.split()),
            'significant_words': len(mots_cles),
            'analysis_details': {
                'emotions': emotions,
                'themes': themes,
                'keywords': mots_cles,
                'explanation': gpt_data.get('raisons', ''),
                'guadeloupe_context': gpt_data.get('contexte_guadeloupe', ''),
                'confidence': confiance,
                'method': 'gpt-4o-mini'
            },
            'analyzed_at': datetime.now().isoformat()
        }

    def _fallback_sentiment_analysis(self, text: str) -> Dict[str, Any]:
        """Analyse de fallback basique en cas d'√©chec GPT"""
        logger.info("üîÑ Utilisation analyse fallback (mots-cl√©s)")
        
        if not text:
            return self._default_sentiment()
        
        # Mots-cl√©s simples pour le fallback
        positive_keywords = ['bon', 'bien', 'excellent', 'r√©ussi', 'succ√®s', 'progr√®s', 'am√©lioration', 'nouveau', 'projet', 'd√©veloppement']
        negative_keywords = ['mauvais', 'probl√®me', '√©chec', 'crise', 'accident', 'mort', 'danger', 'panne', 'difficile', 'grave']
        
        text_lower = text.lower()
        positive_count = sum(1 for word in positive_keywords if word in text_lower)
        negative_count = sum(1 for word in negative_keywords if word in text_lower)
        
        if positive_count > negative_count:
            polarity = 'positive'
            score = 0.3
        elif negative_count > positive_count:
            polarity = 'negative'  
            score = -0.3
        else:
            polarity = 'neutral'
            score = 0.0
        
        return {
            'polarity': polarity,
            'score': score,
            'intensity': 'weak',
            'positive_score': max(0, score),
            'negative_score': abs(min(0, score)),
            'word_count': len(text.split()),
            'significant_words': positive_count + negative_count,
            'analysis_details': {
                'emotions': [],
                'themes': [],
                'keywords': [],
                'explanation': 'Analyse basique par mots-cl√©s (fallback)',
                'guadeloupe_context': '',
                'confidence': 0.5,
                'method': 'keyword_fallback'
            },
            'analyzed_at': datetime.now().isoformat()
        }

    def _default_sentiment(self, error: str = None) -> Dict[str, Any]:
        """Retourner un sentiment par d√©faut"""
        result = {
            'polarity': 'neutral',
            'score': 0.0,
            'intensity': 'weak',
            'positive_score': 0.0,
            'negative_score': 0.0,
            'word_count': 0,
            'significant_words': 0,
            'analysis_details': {
                'emotions': [],
                'themes': [],
                'keywords': [],
                'explanation': '',
                'guadeloupe_context': '',
                'confidence': 0.0,
                'method': 'default'
            },
            'analyzed_at': datetime.now().isoformat()
        }
        
        if error:
            result['error'] = error
        
        return result

    def analyze_articles_batch(self, articles: List[Dict]) -> Dict[str, Any]:
        """Analyser le sentiment d'un lot d'articles avec GPT"""
        try:
            if not articles:
                return {'articles': [], 'summary': self._empty_summary()}
            
            analyzed_articles = []
            sentiment_summary = {
                'positive': 0,
                'negative': 0,
                'neutral': 0,
                'total': len(articles)
            }
            
            all_scores = []
            all_themes = []
            all_emotions = []
            
            # Limiter le nombre d'articles pour contr√¥ler les co√ªts
            max_articles = 50  # Limite pour √©viter des co√ªts √©lev√©s
            articles_to_analyze = articles[:max_articles]
            
            logger.info(f"ü§ñ Analyse GPT batch de {len(articles_to_analyze)} articles")
            
            for i, article in enumerate(articles_to_analyze):
                try:
                    # Analyser le titre (plus important et moins co√ªteux)
                    title = article.get('title', '')
                    content_snippet = article.get('content', '')[:200]  # Premiers 200 caract√®res
                    text_to_analyze = f"{title}. {content_snippet}"
                    
                    title_sentiment = self.analyze_sentiment(text_to_analyze)
                    
                    # Cr√©er l'article analys√©
                    analyzed_article = {
                        **article,
                        'sentiment': title_sentiment,
                        'sentiment_summary': {
                            'polarity': title_sentiment['polarity'],
                            'score': title_sentiment['score'],
                            'intensity': title_sentiment['intensity'],
                            'confidence': title_sentiment['analysis_details']['confidence'],
                            'themes': title_sentiment['analysis_details']['themes'],
                            'emotions': title_sentiment['analysis_details']['emotions']
                        }
                    }
                    
                    analyzed_articles.append(analyzed_article)
                    
                    # Mettre √† jour le r√©sum√©
                    sentiment_summary[title_sentiment['polarity']] += 1
                    all_scores.append(title_sentiment['score'])
                    all_themes.extend(title_sentiment['analysis_details']['themes'])
                    all_emotions.extend(title_sentiment['analysis_details']['emotions'])
                    
                    # Pause pour √©viter les limits de taux
                    if i > 0 and i % 10 == 0:
                        import time
                        time.sleep(1)
                        
                except Exception as e:
                    logger.warning(f"Erreur analyse article {i}: {e}")
                    # Ajouter l'article sans analyse en cas d'erreur
                    analyzed_articles.append({
                        **article,
                        'sentiment': self._default_sentiment(str(e))
                    })
            
            # Calculer les statistiques globales
            avg_score = sum(all_scores) / len(all_scores) if all_scores else 0
            
            from collections import Counter
            theme_counts = Counter(all_themes)
            emotion_counts = Counter(all_emotions)
            
            overall_summary = {
                'total_articles': len(articles_to_analyze),
                'sentiment_distribution': sentiment_summary,
                'average_sentiment_score': round(avg_score, 3),
                'most_common_themes': dict(theme_counts.most_common(5)),
                'most_common_emotions': dict(emotion_counts.most_common(5)),
                'analysis_method': 'gpt-4o-mini',
                'analysis_timestamp': datetime.now().isoformat(),
                'cost_optimization': f'Analys√© {len(articles_to_analyze)}/{len(articles)} articles'
            }
            
            logger.info(f"‚úÖ Analyse GPT batch termin√©e: {len(analyzed_articles)} articles")
            
            return {
                'articles': analyzed_articles,
                'summary': overall_summary
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur analyse batch GPT: {e}")
            return {
                'articles': articles,  # Retourner les articles originaux
                'summary': self._empty_summary(error=str(e))
            }

    def _empty_summary(self, error: str = None) -> Dict[str, Any]:
        """Retourner un r√©sum√© vide"""
        summary = {
            'total_articles': 0,
            'sentiment_distribution': {'positive': 0, 'negative': 0, 'neutral': 0, 'total': 0},
            'average_sentiment_score': 0.0,
            'most_common_themes': {},
            'most_common_emotions': {},
            'analysis_method': 'gpt-4o-mini',
            'analysis_timestamp': datetime.now().isoformat()
        }
        
        if error:
            summary['error'] = error
        
        return summary

# Instance globale
gpt_sentiment_analyzer = GptSentimentAnalyzer()

# Fonctions utilitaires pour compatibilit√©
def analyze_text_sentiment(text: str) -> Dict[str, Any]:
    """Analyser le sentiment d'un texte avec GPT (fonction utilitaire)"""
    return gpt_sentiment_analyzer.analyze_sentiment(text)

def analyze_articles_sentiment(articles: List[Dict]) -> Dict[str, Any]:
    """Analyser le sentiment d'une liste d'articles avec GPT (fonction utilitaire)"""
    return gpt_sentiment_analyzer.analyze_articles_batch(articles)

if __name__ == "__main__":
    # Tests
    test_texts = [
        "Excellent festival de musique cr√©ole √† Pointe-√†-Pitre ! L'ambiance √©tait formidable.",
        "Grave accident de la route en Guadeloupe, plusieurs bless√©s dans un √©tat critique.",
        "Nouvelle √©cole construite √† Basse-Terre pour am√©liorer l'√©ducation des jeunes.",
        "Guy Losbar annonce de nouveaux investissements pour le d√©veloppement durable.",
        "Le Conseil D√©partemental vote le budget pour soutenir les familles en difficult√©."
    ]
    
    print("=== Test du service d'analyse de sentiment GPT ===")
    for text in test_texts:
        result = analyze_text_sentiment(text)
        print(f"\nTexte: {text}")
        print(f"Sentiment: {result['polarity']} (score: {result['score']}, intensit√©: {result['intensity']})")
        print(f"√âmotions: {result['analysis_details']['emotions']}")
        print(f"Th√®mes: {result['analysis_details']['themes']}")
        print(f"Contexte: {result['analysis_details']['guadeloupe_context']}")
        print("---")